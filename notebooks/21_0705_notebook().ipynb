{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "643714a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\81807\\AppData\\Local\\Temp\\ipykernel_14920\\2063891030.py:80: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[0.6        0.2739726  0.65632458 0.7109375  0.62895928 0.62895928\n",
      " 0.65632458 0.62895928 0.7109375  0.71884984 0.6        0.65632458\n",
      " 0.65632458 0.71884984 0.62895928 0.62895928 0.65632458 0.71884984\n",
      " 0.62895928 0.65632458 0.65632458 0.62895928 0.62895928 0.65632458\n",
      " 0.6        0.62895928 0.62895928 0.65632458 0.71884984 0.7109375\n",
      " 0.62895928 0.7109375  0.71884984 0.62895928 0.65632458 0.62895928\n",
      " 0.2739726  0.65632458 0.65632458 0.2739726  0.68376068 0.65632458\n",
      " 0.62895928 0.48275862 0.68376068 0.68376068 0.71884984 0.62895928\n",
      " 0.62895928 0.62895928 0.7109375  0.62895928 0.71884984 0.65632458\n",
      " 0.7109375  0.62895928 0.6        0.62895928 0.7109375  0.65632458\n",
      " 0.62895928 0.62895928 0.71884984 0.71884984 0.68376068 0.7109375\n",
      " 0.68376068 0.65632458 0.62895928 0.62895928 0.62895928 0.62895928\n",
      " 0.68376068 0.6        0.71884984 0.65632458 0.6        0.71884984\n",
      " 0.68376068 0.71884984 0.68376068 0.68376068 0.2739726  0.71884984\n",
      " 0.71884984 0.65632458 0.62895928 0.68376068 0.65632458 0.68376068\n",
      " 0.62895928 0.71884984 0.65632458 0.68376068 0.62895928 0.68376068\n",
      " 0.65632458 0.6        0.62895928 0.7109375  0.68376068 0.71884984\n",
      " 0.2739726  0.65632458 0.6        0.65632458 0.71884984 0.62895928\n",
      " 0.62895928 0.62895928 0.6        0.68376068 0.68376068 0.71884984\n",
      " 0.62895928 0.71884984 0.62895928 0.68376068 0.65632458 0.65632458\n",
      " 0.65632458 0.48275862 0.68376068 0.68376068 0.6        0.71884984\n",
      " 0.65632458 0.62895928 0.62895928 0.62895928 0.71884984 0.68376068\n",
      " 0.62895928 0.71884984 0.65632458 0.71884984 0.71884984 0.62895928\n",
      " 0.65632458 0.7109375  0.7109375  0.6        0.68376068 0.71884984\n",
      " 0.6        0.68376068 0.65632458 0.71884984 0.68376068 0.6\n",
      " 0.65632458 0.7109375  0.62895928 0.68376068 0.6        0.65632458\n",
      " 0.68376068 0.2739726  0.65632458 0.6        0.65632458 0.71884984\n",
      " 0.7109375  0.65632458 0.65632458 0.62895928 0.65632458 0.62895928\n",
      " 0.71884984 0.6        0.6        0.68376068 0.62895928 0.62895928\n",
      " 0.65632458 0.62895928 0.7109375  0.65632458 0.7109375  0.62895928\n",
      " 0.65632458 0.62895928 0.71884984 0.6        0.65632458 0.65632458\n",
      " 0.71884984 0.65632458 0.2739726  0.7109375  0.65632458 0.68376068\n",
      " 0.62895928 0.6        0.48275862 0.2739726  0.7109375  0.71884984\n",
      " 0.65632458 0.62895928 0.65632458 0.65632458 0.71884984 0.6\n",
      " 0.68376068 0.62895928 0.62895928 0.71884984 0.65632458 0.62895928\n",
      " 0.68376068 0.71884984 0.65632458 0.2739726  0.62895928 0.68376068\n",
      " 0.62895928 0.7109375  0.62895928 0.68376068 0.62895928 0.7109375\n",
      " 0.7109375  0.68376068 0.71884984 0.7109375  0.48275862 0.65632458\n",
      " 0.65632458 0.6        0.68376068 0.7109375  0.68376068 0.62895928\n",
      " 0.68376068 0.6        0.65632458 0.71884984 0.71884984 0.71884984\n",
      " 0.62895928 0.7109375  0.7109375  0.65632458 0.62895928 0.65632458\n",
      " 0.71884984 0.7109375  0.62895928 0.68376068 0.65632458 0.68376068\n",
      " 0.2739726  0.62895928 0.65632458 0.62895928 0.6        0.71884984\n",
      " 0.7109375  0.62895928 0.65632458 0.68376068 0.71884984 0.62895928\n",
      " 0.62895928 0.65632458 0.62895928 0.62895928 0.71884984 0.65632458\n",
      " 0.68376068 0.62895928 0.62895928 0.71884984 0.68376068 0.68376068\n",
      " 0.6        0.6        0.62895928 0.62895928 0.71884984 0.48275862\n",
      " 0.62895928 0.65632458 0.62895928 0.65632458 0.65632458 0.62895928\n",
      " 0.62895928 0.62895928 0.7109375  0.62895928 0.6        0.7109375\n",
      " 0.7109375  0.62895928 0.62895928 0.62895928 0.68376068 0.7109375\n",
      " 0.68376068 0.7109375  0.62895928 0.68376068 0.68376068 0.62895928\n",
      " 0.2739726  0.65632458 0.71884984 0.71884984 0.65632458 0.65632458\n",
      " 0.6        0.2739726  0.68376068 0.65632458 0.68376068 0.7109375\n",
      " 0.6        0.65632458 0.2739726  0.68376068 0.62895928 0.68376068\n",
      " 0.62895928 0.2739726  0.65632458 0.68376068 0.48275862 0.65632458\n",
      " 0.68376068 0.62895928 0.65632458 0.7109375  0.7109375  0.71884984\n",
      " 0.6        0.6        0.65632458 0.71884984 0.62895928 0.71884984\n",
      " 0.65632458 0.48275862 0.71884984 0.71884984 0.7109375  0.65632458\n",
      " 0.71884984 0.62895928 0.65632458 0.6        0.62895928 0.7109375\n",
      " 0.7109375  0.62895928 0.65632458 0.7109375  0.65632458 0.71884984\n",
      " 0.68376068 0.65632458 0.65632458 0.65632458 0.62895928 0.62895928\n",
      " 0.7109375  0.62895928 0.6        0.6        0.2739726  0.2739726\n",
      " 0.65632458 0.71884984 0.65632458 0.68376068 0.62895928 0.65632458\n",
      " 0.65632458 0.62895928 0.71884984 0.65632458 0.65632458 0.68376068\n",
      " 0.68376068 0.68376068 0.65632458 0.68376068 0.62895928 0.65632458\n",
      " 0.62895928 0.68376068 0.65632458 0.65632458 0.62895928 0.48275862\n",
      " 0.68376068 0.68376068 0.71884984 0.62895928 0.62895928 0.65632458\n",
      " 0.71884984 0.68376068 0.68376068 0.65632458 0.62895928 0.65632458\n",
      " 0.65632458 0.68376068 0.65632458 0.62895928 0.68376068 0.71884984\n",
      " 0.2739726  0.71884984 0.71884984 0.68376068 0.65632458 0.65632458\n",
      " 0.62895928 0.62895928 0.62895928 0.71884984 0.62895928 0.68376068\n",
      " 0.48275862 0.65632458 0.62895928 0.65632458 0.65632458 0.71884984\n",
      " 0.68376068 0.62895928 0.68376068 0.2739726  0.65632458 0.68376068\n",
      " 0.62895928 0.2739726  0.48275862 0.71884984 0.65632458 0.62895928\n",
      " 0.68376068 0.2739726  0.68376068 0.71884984 0.2739726  0.65632458\n",
      " 0.65632458 0.65632458 0.62895928 0.65632458 0.62895928 0.7109375\n",
      " 0.65632458 0.71884984 0.71884984 0.7109375  0.62895928 0.62895928\n",
      " 0.62895928 0.62895928 0.7109375  0.62895928 0.65632458 0.62895928\n",
      " 0.62895928 0.65632458 0.68376068 0.71884984 0.6        0.68376068\n",
      " 0.65632458 0.65632458 0.62895928 0.71884984 0.65632458 0.65632458\n",
      " 0.71884984 0.71884984 0.62895928 0.62895928 0.6        0.62895928\n",
      " 0.65632458 0.71884984 0.65632458 0.71884984 0.6        0.62895928\n",
      " 0.71884984 0.62895928 0.62895928 0.48275862 0.68376068 0.62895928\n",
      " 0.7109375  0.7109375  0.6        0.62895928 0.62895928 0.6\n",
      " 0.65632458 0.65632458 0.62895928 0.71884984 0.6        0.7109375\n",
      " 0.68376068 0.7109375  0.71884984 0.6        0.6        0.62895928\n",
      " 0.7109375  0.68376068 0.2739726  0.62895928 0.48275862 0.7109375\n",
      " 0.62895928 0.68376068 0.62895928 0.7109375  0.62895928 0.62895928\n",
      " 0.62895928 0.71884984 0.71884984 0.62895928 0.65632458 0.65632458\n",
      " 0.62895928 0.7109375  0.68376068 0.65632458 0.68376068 0.68376068\n",
      " 0.65632458 0.62895928 0.7109375  0.7109375  0.62895928 0.68376068\n",
      " 0.7109375  0.62895928 0.65632458 0.65632458 0.68376068 0.6\n",
      " 0.68376068 0.62895928 0.62895928 0.68376068 0.71884984]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  X.loc[val_idx, \"Position_group_encoded\"] = X.loc[val_idx, \"Position_group\"].map(group_map)\n"
     ]
    }
   ],
   "source": [
    "# ✅ 必要ライブラリ\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from lightgbm import LGBMClassifier\n",
    "import lightgbm as lgb\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# ✅ データ読み込み\n",
    "PATH = '../data/'\n",
    "X = pd.read_csv(PATH + 'train.csv')\n",
    "test = pd.read_csv(PATH + 'test.csv')\n",
    "\n",
    "# ✅ Age 欠損処理\n",
    "X[\"Age_filled\"] = X[\"Age\"].fillna(-1)\n",
    "X[\"Age_missing\"] = X[\"Age\"].isna().astype(int)\n",
    "X = X.drop(columns=[\"Age\"])\n",
    "test[\"Age_filled\"] = test[\"Age\"].fillna(-1)\n",
    "test[\"Age_missing\"] = test[\"Age\"].isna().astype(int)\n",
    "test = test.drop(columns=[\"Age\"])\n",
    "\n",
    "# ✅ 数値カラム欠損補完\n",
    "for col in X.columns:\n",
    "    if X[col].isnull().sum() > 0:\n",
    "        median = X[col].median()\n",
    "        X[col] = X[col].fillna(median)\n",
    "        test[col] = test[col].fillna(median)\n",
    "\n",
    "# ✅ 不要カラム削除\n",
    "X = X.drop(columns=[\"Id\"])\n",
    "test = test.drop(columns=[\"Id\"])\n",
    "\n",
    "# ✅ 目的変数分離\n",
    "y = X[\"Drafted\"]\n",
    "X = X.drop(columns=[\"Drafted\"])\n",
    "\n",
    "# ✅ School, Player_Type, Position_Type 削除\n",
    "X = X.drop(columns=[\"School\", \"Player_Type\", \"Position_Type\"])\n",
    "test = test.drop(columns=[\"School\", \"Player_Type\", \"Position_Type\"])\n",
    "\n",
    "# ✅ Position Target Encoding\n",
    "position_stats = X.copy()\n",
    "position_stats[\"Drafted\"] = y\n",
    "position_target_map = position_stats.groupby(\"Position\")[\"Drafted\"].mean()\n",
    "X[\"Position_encoded\"] = X[\"Position\"].map(position_target_map)\n",
    "test[\"Position_encoded\"] = test[\"Position\"].map(position_target_map)\n",
    "test[\"Position_encoded\"] = test[\"Position_encoded\"].fillna(X[\"Position_encoded\"].mean())\n",
    "\n",
    "# ✅ Position Group Encoding (fold-safe)\n",
    "def map_position_group(pos):\n",
    "    if pos in [\"K\", \"P\", \"LS\"]:\n",
    "        return \"Specialist\"\n",
    "    elif pos in [\"WR\", \"RB\", \"TE\"]:\n",
    "        return \"OffensiveSkill\"\n",
    "    elif pos in [\"OT\", \"OG\", \"C\"]:\n",
    "        return \"OffensiveLine\"\n",
    "    elif pos in [\"DE\", \"DT\"]:\n",
    "        return \"DefensiveLine\"\n",
    "    elif pos in [\"OLB\", \"ILB\"]:\n",
    "        return \"Linebacker\"\n",
    "    elif pos in [\"CB\", \"FS\", \"SS\", \"S\", \"DB\"]:\n",
    "        return \"DefensiveBack\"\n",
    "    elif pos == \"QB\":\n",
    "        return \"Quarterback\"\n",
    "    elif pos == \"FB\":\n",
    "        return \"Fullback\"\n",
    "    else:\n",
    "        return \"Other\"\n",
    "\n",
    "X[\"Position_group\"] = X[\"Position\"].apply(map_position_group)\n",
    "test[\"Position_group\"] = test[\"Position\"].apply(map_position_group)\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "X[\"Position_group_encoded\"] = 0\n",
    "for train_idx, val_idx in kf.split(X):\n",
    "    X_train, y_train = X.iloc[train_idx], y.iloc[train_idx]\n",
    "    group_map = X_train.assign(Drafted=y_train).groupby(\"Position_group\")[\"Drafted\"].mean()\n",
    "    X.loc[val_idx, \"Position_group_encoded\"] = X.loc[val_idx, \"Position_group\"].map(group_map)\n",
    "final_group_map = X.assign(Drafted=y).groupby(\"Position_group\")[\"Drafted\"].mean()\n",
    "test[\"Position_group_encoded\"] = test[\"Position_group\"].map(final_group_map)\n",
    "test[\"Position_group_encoded\"] = test[\"Position_group_encoded\"].fillna(X[\"Position_group_encoded\"].mean())\n",
    "\n",
    "X = X.drop(columns=[\"Position\", \"Position_group\"])\n",
    "test = test.drop(columns=[\"Position\", \"Position_group\"])\n",
    "\n",
    "# ✅ SpeedScore, BurstScore, AgilityScore, ASI, RSA特徴量\n",
    "X[\"Weight_lbs\"] = X[\"Weight\"] * 2.20462\n",
    "test[\"Weight_lbs\"] = test[\"Weight\"] * 2.20462\n",
    "\n",
    "X[\"SpeedScore\"] = X[\"Weight_lbs\"] * (200 / X[\"Sprint_40yd\"]**2)\n",
    "test[\"SpeedScore\"] = test[\"Weight_lbs\"] * (200 / test[\"Sprint_40yd\"]**2)\n",
    "\n",
    "X[\"BurstScore\"] = X[\"Vertical_Jump\"] + X[\"Broad_Jump\"]\n",
    "test[\"BurstScore\"] = test[\"Vertical_Jump\"] + test[\"Broad_Jump\"]\n",
    "\n",
    "X[\"AgilityScore\"] = X[\"Shuttle\"] + X[\"Agility_3cone\"]\n",
    "test[\"AgilityScore\"] = test[\"Shuttle\"] + test[\"Agility_3cone\"]\n",
    "\n",
    "X[\"ASI\"] = 0.5 * X[\"SpeedScore\"] + 0.3 * X[\"BurstScore\"] + 0.2 * X[\"AgilityScore\"]\n",
    "test[\"ASI\"] = 0.5 * test[\"SpeedScore\"] + 0.3 * test[\"BurstScore\"] + 0.2 * test[\"AgilityScore\"]\n",
    "\n",
    "rsa_features = [\"Sprint_40yd\", \"Vertical_Jump\", \"Bench_Press_Reps\", \"Shuttle\", \"Agility_3cone\"]\n",
    "for col in rsa_features:\n",
    "    scaler = MinMaxScaler(feature_range=(0, 10))\n",
    "    if col in [\"Sprint_40yd\", \"Shuttle\", \"Agility_3cone\"]:\n",
    "        X[f\"RSA_{col}\"] = 10 - scaler.fit_transform(X[[col]])\n",
    "        test[f\"RSA_{col}\"] = 10 - scaler.transform(test[[col]])\n",
    "    else:\n",
    "        X[f\"RSA_{col}\"] = scaler.fit_transform(X[[col]])\n",
    "        test[f\"RSA_{col}\"] = scaler.transform(test[[col]])\n",
    "\n",
    "# ✅ BMI\n",
    "X[\"BMI\"] = X[\"Weight\"] / (X[\"Height\"]/100)**2\n",
    "test[\"BMI\"] = test[\"Weight\"] / (test[\"Height\"]/100)**2\n",
    "\n",
    "# ✅ School特徴量（Top, Drafted Count, Drafted Rate TE）\n",
    "df_raw = pd.read_csv(PATH + 'train.csv')\n",
    "test_raw = pd.read_csv(PATH + 'test.csv')\n",
    "X[\"School\"] = df_raw[\"School\"]\n",
    "test[\"School\"] = test_raw[\"School\"]\n",
    "\n",
    "school_stats = X.copy()\n",
    "school_stats[\"Drafted\"] = y\n",
    "school_agg = school_stats.groupby(\"School\")[\"Drafted\"].agg([\"sum\", \"count\"])\n",
    "school_agg[\"Drafted_Rate\"] = school_agg[\"sum\"] / school_agg[\"count\"]\n",
    "\n",
    "top_n = 20\n",
    "top_schools = school_agg[\"sum\"].sort_values(ascending=False).head(top_n).index.tolist()\n",
    "\n",
    "X[\"School_Top\"] = X[\"School\"].isin(top_schools).astype(int)\n",
    "test[\"School_Top\"] = test[\"School\"].isin(top_schools).astype(int)\n",
    "\n",
    "X[\"School_Drafted_Count\"] = X[\"School\"].map(school_agg[\"sum\"])\n",
    "test[\"School_Drafted_Count\"] = test[\"School\"].map(school_agg[\"sum\"])\n",
    "test[\"School_Drafted_Count\"] = test[\"School_Drafted_Count\"].fillna(0)\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "X[\"School_Drafted_Rate_TE\"] = 0.0\n",
    "for train_idx, val_idx in kf.split(X):\n",
    "    X_train, y_train = X.iloc[train_idx], y.iloc[train_idx]\n",
    "    rate_map = X_train.assign(Drafted=y_train).groupby(\"School\")[\"Drafted\"].mean()\n",
    "    X.loc[val_idx, \"School_Drafted_Rate_TE\"] = X.loc[val_idx, \"School\"].map(rate_map)\n",
    "final_rate_map = X.assign(Drafted=y).groupby(\"School\")[\"Drafted\"].mean()\n",
    "test[\"School_Drafted_Rate_TE\"] = test[\"School\"].map(final_rate_map)\n",
    "test[\"School_Drafted_Rate_TE\"] = test[\"School_Drafted_Rate_TE\"].fillna(y.mean())\n",
    "\n",
    "X = X.drop(columns=[\"School\"])\n",
    "test = test.drop(columns=[\"School\"])\n",
    "\n",
    "\n",
    "X[\"Speed_BMI_Ratio\"] = X[\"SpeedScore\"] / X[\"BMI\"]\n",
    "test[\"Speed_BMI_Ratio\"] = test[\"SpeedScore\"] / test[\"BMI\"]\n",
    "\n",
    "X[\"Sprint_ASI\"] = X[\"Sprint_40yd\"] * X[\"ASI\"]\n",
    "test[\"Sprint_ASI\"] = test[\"Sprint_40yd\"] * test[\"ASI\"]\n",
    "\n",
    "X[\"Age_Speed\"] = X[\"Age_filled\"] * X[\"SpeedScore\"]\n",
    "test[\"Age_Speed\"] = test[\"Age_filled\"] * test[\"SpeedScore\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb599ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ 高相関特徴量削除\n",
    "drop_cols_high_corr = [\n",
    "    \"Weight_lbs\",\n",
    "    \"RSA_Sprint_40yd\",\n",
    "    \"RSA_Vertical_Jump\",\n",
    "    \"RSA_Bench_Press_Reps\",\n",
    "    \"RSA_Agility_3cone\",\n",
    "    \"RSA_Shuttle\",\n",
    "    \"SpeedScore\",\n",
    "    \"Age_missing\"\n",
    "]\n",
    "X = X.drop(columns=drop_cols_high_corr)\n",
    "test = test.drop(columns=drop_cols_high_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed914d17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 高相関特徴量 ['Broad_Jump', 'Agility_3cone', 'Age_filled', 'Sprint_ASI', 'Shuttle', 'Weight', 'Position_encoded', 'Vertical_Jump'] を削除しました。\n",
      "✅ 現在の特徴量数: 14\n"
     ]
    }
   ],
   "source": [
    "# ✅ 高相関特徴量（再確認）削除\n",
    "drop_cols_high_corr_v2 = [\n",
    "    \"Broad_Jump\",\n",
    "    \"Agility_3cone\",\n",
    "    \"Age_filled\",\n",
    "    \"Sprint_ASI\",\n",
    "    \"Shuttle\",\n",
    "    \"Weight\",\n",
    "    \"Position_encoded\",\n",
    "    \"Vertical_Jump\"\n",
    "]\n",
    "X = X.drop(columns=drop_cols_high_corr_v2)\n",
    "test = test.drop(columns=drop_cols_high_corr_v2)\n",
    "\n",
    "print(f\"✅ 高相関特徴量 {drop_cols_high_corr_v2} を削除しました。\")\n",
    "print(f\"✅ 現在の特徴量数: {X.shape[1]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e0fcea",
   "metadata": {},
   "source": [
    "```python\n",
    "import optuna\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        \"iterations\": trial.suggest_int(\"iterations\", 200, 1000),\n",
    "        \"depth\": trial.suggest_int(\"depth\", 4, 10),\n",
    "        \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.01, 0.2),\n",
    "        \"l2_leaf_reg\": trial.suggest_loguniform(\"l2_leaf_reg\", 1e-2, 10),\n",
    "        \"bagging_temperature\": trial.suggest_uniform(\"bagging_temperature\", 0, 1),\n",
    "        \"random_strength\": trial.suggest_uniform(\"random_strength\", 0, 1),\n",
    "        \"border_count\": trial.suggest_int(\"border_count\", 32, 255),\n",
    "        \"task_type\": \"CPU\",  # GPUがなければCPUに変更\n",
    "        \"verbose\": 0,\n",
    "        \"random_state\": 42\n",
    "    }\n",
    "\n",
    "    cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    aucs = []\n",
    "\n",
    "    for train_idx, valid_idx in cv.split(X, y):\n",
    "        X_train, X_valid = X.iloc[train_idx], X.iloc[valid_idx]\n",
    "        y_train, y_valid = y.iloc[train_idx], y.iloc[valid_idx]\n",
    "\n",
    "        train_pool = Pool(X_train, y_train)\n",
    "        valid_pool = Pool(X_valid, y_valid)\n",
    "\n",
    "        model = CatBoostClassifier(**params)\n",
    "        model.fit(train_pool, eval_set=valid_pool, early_stopping_rounds=30, verbose=0)\n",
    "\n",
    "        y_valid_pred = model.predict_proba(X_valid)[:, 1]\n",
    "        auc = roc_auc_score(y_valid, y_valid_pred)\n",
    "        aucs.append(auc)\n",
    "\n",
    "    return np.mean(aucs)\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "print(\"✅ Best params:\", study.best_params)\n",
    "print(\"✅ Best CV AUC:\", study.best_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30bc487c",
   "metadata": {},
   "source": [
    "✅ Best params: {'iterations': 855, 'depth': 4, 'learning_rate': 0.19592013244663484, 'l2_leaf_reg': 1.481074845788448, 'bagging_temperature': 0.7801385067591142, 'random_strength': 0.5288429489812297, 'border_count': 153}\n",
    "✅ Best CV AUC: 0.843772622546801\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ffff1f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47085373",
   "metadata": {},
   "source": [
    "```python\n",
    "\n",
    "import optuna\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np\n",
    "\n",
    "# ✅ Optuna objective\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        \"n_estimators\": 1000,\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 8),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.1, log=True),\n",
    "        \"subsample\": trial.suggest_uniform(\"subsample\", 0.6, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_uniform(\"colsample_bytree\", 0.6, 1.0),\n",
    "        \"gamma\": trial.suggest_uniform(\"gamma\", 0, 5),\n",
    "        \"reg_alpha\": trial.suggest_loguniform(\"reg_alpha\", 1e-3, 10.0),\n",
    "        \"reg_lambda\": trial.suggest_loguniform(\"reg_lambda\", 1e-3, 10.0),\n",
    "        \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 10),\n",
    "        \"random_state\": 42,\n",
    "        \"tree_method\": \"hist\",  # CPUなら \"hist\"\n",
    "        \"use_label_encoder\": False,\n",
    "        \"eval_metric\": \"auc\"\n",
    "    }\n",
    "    \n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    aucs = []\n",
    "\n",
    "    for train_idx, valid_idx in cv.split(X, y):\n",
    "        X_train, X_valid = X.iloc[train_idx], X.iloc[valid_idx]\n",
    "        y_train, y_valid = y.iloc[train_idx], y.iloc[valid_idx]\n",
    "\n",
    "        model = XGBClassifier(**params)\n",
    "\n",
    "        # ✅ カラム数エラー防止のため eval_set 使用時は verbose=0\n",
    "        model.fit(\n",
    "            X_train, y_train,\n",
    "            eval_set=[(X_valid, y_valid)],\n",
    "            verbose=0,\n",
    "        )\n",
    "\n",
    "        y_valid_pred = model.predict_proba(X_valid)[:, 1]\n",
    "        auc = roc_auc_score(y_valid, y_valid_pred)\n",
    "        aucs.append(auc)\n",
    "\n",
    "    return np.mean(aucs)\n",
    "\n",
    "# ✅ Optuna 実行\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=30)\n",
    "\n",
    "print(f\"✅ Best params: {study.best_params}\")\n",
    "print(f\"✅ Best CV AUC: {study.best_value:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65142387",
   "metadata": {},
   "source": [
    "✅ Best params: {'max_depth': 3, 'learning_rate': 0.017970318546566402, 'subsample': 0.7207516023173938, 'colsample_bytree': 0.7336465986159872, 'gamma': 2.3743521750700465, 'reg_alpha': 0.19615972164906634, 'reg_lambda': 0.011650130960748368, 'min_child_weight': 1}\n",
    "✅ Best CV AUC: 0.843695"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c6219b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ CatBoost 再学習開始\n",
      "✅ [CatBoost] Fold 1 - Train AUC: 0.9246, Validation AUC: 0.8613\n",
      "✅ [CatBoost] Fold 2 - Train AUC: 0.8799, Validation AUC: 0.8493\n",
      "✅ [CatBoost] Fold 3 - Train AUC: 0.9016, Validation AUC: 0.8327\n",
      "✅ [CatBoost] Fold 4 - Train AUC: 0.9306, Validation AUC: 0.8221\n",
      "✅ [CatBoost] Fold 5 - Train AUC: 0.9185, Validation AUC: 0.8571\n",
      "\n",
      "✅ [CatBoost] Average Train AUC: 0.9110\n",
      "✅ [CatBoost] Average Validation AUC: 0.8445\n",
      "\n",
      "✅ XGBoost 再学習開始\n",
      "[0]\tvalid-auc:0.66791\n",
      "[100]\tvalid-auc:0.83833\n",
      "[200]\tvalid-auc:0.84610\n",
      "[300]\tvalid-auc:0.85214\n",
      "[400]\tvalid-auc:0.85799\n",
      "[449]\tvalid-auc:0.85806\n",
      "✅ [XGBoost] Fold 1 - Train AUC: 0.9089, Validation AUC: 0.8581\n",
      "[0]\tvalid-auc:0.63910\n",
      "[100]\tvalid-auc:0.84350\n",
      "[200]\tvalid-auc:0.85035\n",
      "[226]\tvalid-auc:0.85058\n",
      "✅ [XGBoost] Fold 2 - Train AUC: 0.8788, Validation AUC: 0.8506\n",
      "[0]\tvalid-auc:0.67133\n",
      "[38]\tvalid-auc:0.81951\n",
      "✅ [XGBoost] Fold 3 - Train AUC: 0.8535, Validation AUC: 0.8203\n",
      "[0]\tvalid-auc:0.66296\n",
      "[36]\tvalid-auc:0.79016\n",
      "✅ [XGBoost] Fold 4 - Train AUC: 0.8551, Validation AUC: 0.7908\n",
      "[0]\tvalid-auc:0.68413\n",
      "[53]\tvalid-auc:0.84293\n",
      "✅ [XGBoost] Fold 5 - Train AUC: 0.8484, Validation AUC: 0.8426\n",
      "\n",
      "✅ [XGBoost] Average Train AUC: 0.8689\n",
      "✅ [XGBoost] Average Validation AUC: 0.8325\n"
     ]
    }
   ],
   "source": [
    "# ✅ 必要ライブラリインポート\n",
    "from catboost import CatBoostClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "\n",
    "# ✅ CatBoost 最適化パラメータ設定\n",
    "cat_model = CatBoostClassifier(\n",
    "    iterations=855,\n",
    "    depth=4,\n",
    "    learning_rate=0.19592013244663484,\n",
    "    l2_leaf_reg=1.481074845788448,\n",
    "    bagging_temperature=0.7801385067591142,\n",
    "    random_strength=0.5288429489812297,\n",
    "    border_count=153,\n",
    "    eval_metric='AUC',\n",
    "    random_seed=42,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "# ✅ XGBoost 最適化パラメータ設定\n",
    "xgb_params = {\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'auc',\n",
    "    'max_depth': 3,\n",
    "    'learning_rate': 0.017970318546566402,\n",
    "    'subsample': 0.7207516023173938,\n",
    "    'colsample_bytree': 0.7336465986159872,\n",
    "    'gamma': 2.3743521750700465,\n",
    "    'reg_alpha': 0.19615972164906634,\n",
    "    'reg_lambda': 0.011650130960748368,\n",
    "    'min_child_weight': 1,\n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# ✅ CatBoost 再学習・評価\n",
    "train_aucs_cat, val_aucs_cat = [], []\n",
    "print(\"✅ CatBoost 再学習開始\")\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(X)):\n",
    "    X_train, X_valid = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_valid = y.iloc[train_idx], y.iloc[val_idx]\n",
    "    \n",
    "    cat_model.fit(X_train, y_train, eval_set=(X_valid, y_valid), early_stopping_rounds=30, use_best_model=True)\n",
    "    \n",
    "    y_train_pred = cat_model.predict_proba(X_train)[:, 1]\n",
    "    y_valid_pred = cat_model.predict_proba(X_valid)[:, 1]\n",
    "    \n",
    "    train_auc = roc_auc_score(y_train, y_train_pred)\n",
    "    val_auc = roc_auc_score(y_valid, y_valid_pred)\n",
    "    train_aucs_cat.append(train_auc)\n",
    "    val_aucs_cat.append(val_auc)\n",
    "    print(f\"✅ [CatBoost] Fold {fold+1} - Train AUC: {train_auc:.4f}, Validation AUC: {val_auc:.4f}\")\n",
    "print(f\"\\n✅ [CatBoost] Average Train AUC: {np.mean(train_aucs_cat):.4f}\")\n",
    "print(f\"✅ [CatBoost] Average Validation AUC: {np.mean(val_aucs_cat):.4f}\\n\")\n",
    "\n",
    "# ✅ XGBoost 再学習・評価\n",
    "train_aucs_xgb, val_aucs_xgb = [], []\n",
    "print(\"✅ XGBoost 再学習開始\")\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(X)):\n",
    "    X_train, X_valid = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_valid = y.iloc[train_idx], y.iloc[val_idx]\n",
    "    \n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "    dvalid = xgb.DMatrix(X_valid, label=y_valid)\n",
    "    \n",
    "    model = xgb.train(\n",
    "        xgb_params,\n",
    "        dtrain,\n",
    "        num_boost_round=2000,\n",
    "        evals=[(dvalid, 'valid')],\n",
    "        early_stopping_rounds=30,\n",
    "        verbose_eval=100\n",
    "    )\n",
    "    \n",
    "    y_train_pred = model.predict(dtrain)\n",
    "    y_valid_pred = model.predict(dvalid)\n",
    "    \n",
    "    train_auc = roc_auc_score(y_train, y_train_pred)\n",
    "    val_auc = roc_auc_score(y_valid, y_valid_pred)\n",
    "    train_aucs_xgb.append(train_auc)\n",
    "    val_aucs_xgb.append(val_auc)\n",
    "    print(f\"✅ [XGBoost] Fold {fold+1} - Train AUC: {train_auc:.4f}, Validation AUC: {val_auc:.4f}\")\n",
    "print(f\"\\n✅ [XGBoost] Average Train AUC: {np.mean(train_aucs_xgb):.4f}\")\n",
    "print(f\"✅ [XGBoost] Average Validation AUC: {np.mean(val_aucs_xgb):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c3300e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ LightGBM 最適化パラメータで再学習開始\n",
      "[LightGBM] [Info] Number of positive: 1445, number of negative: 779\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001044 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1769\n",
      "[LightGBM] [Info] Number of data points in the train set: 2224, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.649730 -> initscore=0.617854\n",
      "[LightGBM] [Info] Start training from score 0.617854\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[100]\tvalid_0's auc: 0.848193\tvalid_0's binary_logloss: 0.428866\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[200]\tvalid_0's auc: 0.853134\tvalid_0's binary_logloss: 0.418821\n",
      "Early stopping, best iteration is:\n",
      "[192]\tvalid_0's auc: 0.853584\tvalid_0's binary_logloss: 0.419348\n",
      "✅ [LightGBM] Fold 1 - Train AUC: 0.8907, Validation AUC: 0.8536\n",
      "[LightGBM] [Info] Number of positive: 1448, number of negative: 777\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000229 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1777\n",
      "[LightGBM] [Info] Number of data points in the train set: 2225, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.650787 -> initscore=0.622498\n",
      "[LightGBM] [Info] Start training from score 0.622498\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[100]\tvalid_0's auc: 0.839521\tvalid_0's binary_logloss: 0.438811\n",
      "Early stopping, best iteration is:\n",
      "[119]\tvalid_0's auc: 0.840782\tvalid_0's binary_logloss: 0.435846\n",
      "✅ [LightGBM] Fold 2 - Train AUC: 0.8829, Validation AUC: 0.8408\n",
      "[LightGBM] [Info] Number of positive: 1442, number of negative: 783\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000213 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1782\n",
      "[LightGBM] [Info] Number of data points in the train set: 2225, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.648090 -> initscore=0.610654\n",
      "[LightGBM] [Info] Start training from score 0.610654\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[32]\tvalid_0's auc: 0.810256\tvalid_0's binary_logloss: 0.497419\n",
      "✅ [LightGBM] Fold 3 - Train AUC: 0.8572, Validation AUC: 0.8103\n",
      "[LightGBM] [Info] Number of positive: 1438, number of negative: 787\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000202 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 2225, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.646292 -> initscore=0.602780\n",
      "[LightGBM] [Info] Start training from score 0.602780\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[100]\tvalid_0's auc: 0.794191\tvalid_0's binary_logloss: 0.457411\n",
      "Early stopping, best iteration is:\n",
      "[147]\tvalid_0's auc: 0.797217\tvalid_0's binary_logloss: 0.455413\n",
      "✅ [LightGBM] Fold 4 - Train AUC: 0.8899, Validation AUC: 0.7972\n",
      "[LightGBM] [Info] Number of positive: 1439, number of negative: 786\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000213 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1779\n",
      "[LightGBM] [Info] Number of data points in the train set: 2225, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.646742 -> initscore=0.604747\n",
      "[LightGBM] [Info] Start training from score 0.604747\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[100]\tvalid_0's auc: 0.838213\tvalid_0's binary_logloss: 0.43218\n",
      "Early stopping, best iteration is:\n",
      "[81]\tvalid_0's auc: 0.8391\tvalid_0's binary_logloss: 0.435316\n",
      "✅ [LightGBM] Fold 5 - Train AUC: 0.8742, Validation AUC: 0.8391\n",
      "\n",
      "✅ [LightGBM] Average Train AUC: 0.8790\n",
      "✅ [LightGBM] Average Validation AUC: 0.8282\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np\n",
    "\n",
    "# ✅ LightGBM 最適化パラメータ（直近ベストスコア使用）\n",
    "model_lgb = LGBMClassifier(\n",
    "    max_depth=6,\n",
    "    num_leaves=10,\n",
    "    min_child_samples=38,\n",
    "    reg_alpha=8.18,\n",
    "    reg_lambda=8.07,\n",
    "    learning_rate=0.0442,\n",
    "    n_estimators=1000,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "train_aucs_lgb = []\n",
    "val_aucs_lgb = []\n",
    "\n",
    "print(\"✅ LightGBM 最適化パラメータで再学習開始\")\n",
    "\n",
    "for fold, (train_idx, valid_idx) in enumerate(kf.split(X)):\n",
    "    X_train, X_valid = X.iloc[train_idx], X.iloc[valid_idx]\n",
    "    y_train, y_valid = y.iloc[train_idx], y.iloc[valid_idx]\n",
    "\n",
    "    model_lgb.fit(\n",
    "        X_train, y_train,\n",
    "        eval_set=[(X_valid, y_valid)],\n",
    "        eval_metric='auc',\n",
    "        callbacks=[lgb.early_stopping(stopping_rounds=30), lgb.log_evaluation(100)]\n",
    "    )\n",
    "\n",
    "    y_train_pred = model_lgb.predict_proba(X_train)[:, 1]\n",
    "    y_valid_pred = model_lgb.predict_proba(X_valid)[:, 1]\n",
    "\n",
    "    train_auc = roc_auc_score(y_train, y_train_pred)\n",
    "    val_auc = roc_auc_score(y_valid, y_valid_pred)\n",
    "\n",
    "    train_aucs_lgb.append(train_auc)\n",
    "    val_aucs_lgb.append(val_auc)\n",
    "\n",
    "    print(f\"✅ [LightGBM] Fold {fold + 1} - Train AUC: {train_auc:.4f}, Validation AUC: {val_auc:.4f}\")\n",
    "\n",
    "print(f\"\\n✅ [LightGBM] Average Train AUC: {np.mean(train_aucs_lgb):.4f}\")\n",
    "print(f\"✅ [LightGBM] Average Validation AUC: {np.mean(val_aucs_lgb):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d643b5ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ アンサンブル (Weighted Voting + Stacking) 開始\n",
      "✅ [CatBoost] Fold 1 - Train AUC: 0.9246, Validation AUC: 0.8613\n",
      "[0]\tvalid-auc:0.66791\n",
      "[100]\tvalid-auc:0.83833\n",
      "[200]\tvalid-auc:0.84610\n",
      "[300]\tvalid-auc:0.85214\n",
      "[400]\tvalid-auc:0.85799\n",
      "[448]\tvalid-auc:0.85806\n",
      "✅ [XGBoost] Fold 1 - Train AUC: 0.9089, Validation AUC: 0.8581\n",
      "[LightGBM] [Info] Number of positive: 1445, number of negative: 779\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000465 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1769\n",
      "[LightGBM] [Info] Number of data points in the train set: 2224, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.649730 -> initscore=0.617854\n",
      "[LightGBM] [Info] Start training from score 0.617854\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[100]\tvalid_0's auc: 0.848193\tvalid_0's binary_logloss: 0.428866\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[200]\tvalid_0's auc: 0.853134\tvalid_0's binary_logloss: 0.418821\n",
      "Early stopping, best iteration is:\n",
      "[192]\tvalid_0's auc: 0.853584\tvalid_0's binary_logloss: 0.419348\n",
      "✅ [LightGBM] Fold 1 - Train AUC: 0.8907, Validation AUC: 0.8536\n",
      "✅ [CatBoost] Fold 2 - Train AUC: 0.8799, Validation AUC: 0.8493\n",
      "[0]\tvalid-auc:0.63910\n",
      "[100]\tvalid-auc:0.84350\n",
      "[200]\tvalid-auc:0.85035\n",
      "[226]\tvalid-auc:0.85058\n",
      "✅ [XGBoost] Fold 2 - Train AUC: 0.8788, Validation AUC: 0.8506\n",
      "[LightGBM] [Info] Number of positive: 1448, number of negative: 777\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000289 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1777\n",
      "[LightGBM] [Info] Number of data points in the train set: 2225, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.650787 -> initscore=0.622498\n",
      "[LightGBM] [Info] Start training from score 0.622498\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[100]\tvalid_0's auc: 0.839521\tvalid_0's binary_logloss: 0.438811\n",
      "Early stopping, best iteration is:\n",
      "[119]\tvalid_0's auc: 0.840782\tvalid_0's binary_logloss: 0.435846\n",
      "✅ [LightGBM] Fold 2 - Train AUC: 0.8829, Validation AUC: 0.8408\n",
      "✅ [CatBoost] Fold 3 - Train AUC: 0.9016, Validation AUC: 0.8327\n",
      "[0]\tvalid-auc:0.67133\n",
      "[39]\tvalid-auc:0.82026\n",
      "✅ [XGBoost] Fold 3 - Train AUC: 0.8535, Validation AUC: 0.8203\n",
      "[LightGBM] [Info] Number of positive: 1442, number of negative: 783\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000199 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1782\n",
      "[LightGBM] [Info] Number of data points in the train set: 2225, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.648090 -> initscore=0.610654\n",
      "[LightGBM] [Info] Start training from score 0.610654\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[32]\tvalid_0's auc: 0.810256\tvalid_0's binary_logloss: 0.497419\n",
      "✅ [LightGBM] Fold 3 - Train AUC: 0.8572, Validation AUC: 0.8103\n",
      "✅ [CatBoost] Fold 4 - Train AUC: 0.9306, Validation AUC: 0.8221\n",
      "[0]\tvalid-auc:0.66296\n",
      "[36]\tvalid-auc:0.79016\n",
      "✅ [XGBoost] Fold 4 - Train AUC: 0.8551, Validation AUC: 0.7908\n",
      "[LightGBM] [Info] Number of positive: 1438, number of negative: 787\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000248 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1778\n",
      "[LightGBM] [Info] Number of data points in the train set: 2225, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.646292 -> initscore=0.602780\n",
      "[LightGBM] [Info] Start training from score 0.602780\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[100]\tvalid_0's auc: 0.794191\tvalid_0's binary_logloss: 0.457411\n",
      "Early stopping, best iteration is:\n",
      "[147]\tvalid_0's auc: 0.797217\tvalid_0's binary_logloss: 0.455413\n",
      "✅ [LightGBM] Fold 4 - Train AUC: 0.8899, Validation AUC: 0.7972\n",
      "✅ [CatBoost] Fold 5 - Train AUC: 0.9185, Validation AUC: 0.8571\n",
      "[0]\tvalid-auc:0.68413\n",
      "[53]\tvalid-auc:0.84293\n",
      "✅ [XGBoost] Fold 5 - Train AUC: 0.8484, Validation AUC: 0.8426\n",
      "[LightGBM] [Info] Number of positive: 1439, number of negative: 786\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000323 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1779\n",
      "[LightGBM] [Info] Number of data points in the train set: 2225, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.646742 -> initscore=0.604747\n",
      "[LightGBM] [Info] Start training from score 0.604747\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[100]\tvalid_0's auc: 0.838213\tvalid_0's binary_logloss: 0.43218\n",
      "Early stopping, best iteration is:\n",
      "[81]\tvalid_0's auc: 0.8391\tvalid_0's binary_logloss: 0.435316\n",
      "✅ [LightGBM] Fold 5 - Train AUC: 0.8742, Validation AUC: 0.8391\n",
      "\n",
      "✅ [CatBoost] Average Train AUC: 0.9110\n",
      "✅ [CatBoost] Average Validation AUC: 0.8445\n",
      "\n",
      "✅ [XGBoost] Average Train AUC: 0.8689\n",
      "✅ [XGBoost] Average Validation AUC: 0.8325\n",
      "\n",
      "✅ [LightGBM] Average Train AUC: 0.8790\n",
      "✅ [LightGBM] Average Validation AUC: 0.8282\n",
      "\n",
      "✅ [Weighted Voting] Validation AUC: 0.8418\n",
      "✅ [Stacking] Validation AUC: 0.8448\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "import xgboost as xgb\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "assert isinstance(y, pd.Series)  # 安全確認\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "oof_cat = np.zeros(len(X))\n",
    "oof_xgb = np.zeros(len(X))\n",
    "oof_lgb = np.zeros(len(X))\n",
    "y_true = np.zeros(len(X))\n",
    "\n",
    "# ✅ CatBoost 最適化済パラメータ\n",
    "cat_model = CatBoostClassifier(\n",
    "    iterations=855,\n",
    "    depth=4,\n",
    "    learning_rate=0.19592013244663484,\n",
    "    l2_leaf_reg=1.481074845788448,\n",
    "    bagging_temperature=0.7801385067591142,\n",
    "    random_strength=0.5288429489812297,\n",
    "    border_count=153,\n",
    "    eval_metric='AUC',\n",
    "    random_seed=42,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "# ✅ XGBoost 最適化済パラメータ\n",
    "xgb_params = {\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'auc',\n",
    "    'max_depth': 3,\n",
    "    'learning_rate': 0.017970318546566402,\n",
    "    'subsample': 0.7207516023173938,\n",
    "    'colsample_bytree': 0.7336465986159872,\n",
    "    'gamma': 2.3743521750700465,\n",
    "    'reg_alpha': 0.19615972164906634,\n",
    "    'reg_lambda': 0.011650130960748368,\n",
    "    'min_child_weight': 1,\n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "# ✅ LightGBM 最適化済パラメータ\n",
    "lgb_model = LGBMClassifier(\n",
    "    max_depth=6,\n",
    "    num_leaves=10,\n",
    "    min_child_samples=38,\n",
    "    reg_alpha=8.18,\n",
    "    reg_lambda=8.07,\n",
    "    learning_rate=0.0442,\n",
    "    n_estimators=1000,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"✅ アンサンブル (Weighted Voting + Stacking) 開始\")\n",
    "\n",
    "train_aucs_cat, val_aucs_cat = [], []\n",
    "train_aucs_xgb, val_aucs_xgb = [], []\n",
    "train_aucs_lgb, val_aucs_lgb = [], []\n",
    "\n",
    "for fold, (train_idx, valid_idx) in enumerate(kf.split(X)):\n",
    "    X_train, X_valid = X.iloc[train_idx], X.iloc[valid_idx]\n",
    "    y_train, y_valid = y.iloc[train_idx], y.iloc[valid_idx]\n",
    "\n",
    "    # ✅ CatBoost\n",
    "    cat_model.fit(X_train, y_train, eval_set=(X_valid, y_valid),\n",
    "                  early_stopping_rounds=30, use_best_model=True)\n",
    "    oof_cat[valid_idx] = cat_model.predict_proba(X_valid)[:, 1]\n",
    "    y_train_pred = cat_model.predict_proba(X_train)[:, 1]\n",
    "    y_valid_pred = oof_cat[valid_idx]\n",
    "    train_auc = roc_auc_score(y_train, y_train_pred)\n",
    "    val_auc = roc_auc_score(y_valid, y_valid_pred)\n",
    "    train_aucs_cat.append(train_auc)\n",
    "    val_aucs_cat.append(val_auc)\n",
    "    print(f\"✅ [CatBoost] Fold {fold+1} - Train AUC: {train_auc:.4f}, Validation AUC: {val_auc:.4f}\")\n",
    "\n",
    "    # ✅ XGBoost\n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "    dvalid = xgb.DMatrix(X_valid, label=y_valid)\n",
    "    xgb_model = xgb.train(\n",
    "        xgb_params,\n",
    "        dtrain,\n",
    "        num_boost_round=2000,\n",
    "        evals=[(dvalid, 'valid')],\n",
    "        early_stopping_rounds=30,\n",
    "        verbose_eval=100\n",
    "    )\n",
    "    oof_xgb[valid_idx] = xgb_model.predict(dvalid)\n",
    "    y_train_pred = xgb_model.predict(dtrain)\n",
    "    y_valid_pred = oof_xgb[valid_idx]\n",
    "    train_auc = roc_auc_score(y_train, y_train_pred)\n",
    "    val_auc = roc_auc_score(y_valid, y_valid_pred)\n",
    "    train_aucs_xgb.append(train_auc)\n",
    "    val_aucs_xgb.append(val_auc)\n",
    "    print(f\"✅ [XGBoost] Fold {fold+1} - Train AUC: {train_auc:.4f}, Validation AUC: {val_auc:.4f}\")\n",
    "\n",
    "    # ✅ LightGBM\n",
    "    lgb_model.fit(\n",
    "        X_train, y_train,\n",
    "        eval_set=[(X_valid, y_valid)],\n",
    "        eval_metric='auc',\n",
    "        callbacks=[lgb.early_stopping(stopping_rounds=30), lgb.log_evaluation(100)]\n",
    "    )\n",
    "    oof_lgb[valid_idx] = lgb_model.predict_proba(X_valid)[:, 1]\n",
    "    y_train_pred = lgb_model.predict_proba(X_train)[:, 1]\n",
    "    y_valid_pred = oof_lgb[valid_idx]\n",
    "    train_auc = roc_auc_score(y_train, y_train_pred)\n",
    "    val_auc = roc_auc_score(y_valid, y_valid_pred)\n",
    "    train_aucs_lgb.append(train_auc)\n",
    "    val_aucs_lgb.append(val_auc)\n",
    "    print(f\"✅ [LightGBM] Fold {fold+1} - Train AUC: {train_auc:.4f}, Validation AUC: {val_auc:.4f}\")\n",
    "\n",
    "    y_true[valid_idx] = y_valid\n",
    "\n",
    "# ✅ Fold平均表示\n",
    "print(f\"\\n✅ [CatBoost] Average Train AUC: {np.mean(train_aucs_cat):.4f}\")\n",
    "print(f\"✅ [CatBoost] Average Validation AUC: {np.mean(val_aucs_cat):.4f}\")\n",
    "\n",
    "print(f\"\\n✅ [XGBoost] Average Train AUC: {np.mean(train_aucs_xgb):.4f}\")\n",
    "print(f\"✅ [XGBoost] Average Validation AUC: {np.mean(val_aucs_xgb):.4f}\")\n",
    "\n",
    "print(f\"\\n✅ [LightGBM] Average Train AUC: {np.mean(train_aucs_lgb):.4f}\")\n",
    "print(f\"✅ [LightGBM] Average Validation AUC: {np.mean(val_aucs_lgb):.4f}\")\n",
    "\n",
    "# ✅ Weighted Soft Voting\n",
    "weights = [1, 1, 1]\n",
    "ensemble_probs = (weights[0] * oof_cat + weights[1] * oof_xgb + weights[2] * oof_lgb) / sum(weights)\n",
    "auc_voting = roc_auc_score(y_true, ensemble_probs)\n",
    "print(f\"\\n✅ [Weighted Voting] Validation AUC: {auc_voting:.4f}\")\n",
    "\n",
    "# ✅ Stacking\n",
    "stack_X = np.vstack([oof_cat, oof_xgb, oof_lgb]).T\n",
    "meta_model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "meta_model.fit(stack_X, y_true)\n",
    "meta_preds = meta_model.predict_proba(stack_X)[:, 1]\n",
    "auc_stacking = roc_auc_score(y_true, meta_preds)\n",
    "print(f\"✅ [Stacking] Validation AUC: {auc_stacking:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd30539b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ アンサンブル提出ファイルを保存しました: c:\\Users\\81807\\Desktop\\Kaggle\\GCI②(NFL Draft Prediction)\\submissions\\submission_21_0705().csv\n"
     ]
    }
   ],
   "source": [
    "# ✅ 提出用ファイル作成処理（アンサンブル予測）\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "import re\n",
    "\n",
    "# ✅ テストデータ再読み込み（Id復元用）\n",
    "original_test = pd.read_csv(PATH + \"test.csv\")\n",
    "\n",
    "# ✅ 提出用特徴量列（現在のX.columnsで固定）\n",
    "feature_cols = X.columns.tolist()\n",
    "X_test = test[feature_cols]\n",
    "\n",
    "# ✅ それぞれモデルで予測\n",
    "\n",
    "# CatBoost\n",
    "cat_preds = cat_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# XGBoost\n",
    "dtest = xgb.DMatrix(X_test)\n",
    "xgb_preds = xgb_model.predict(dtest)\n",
    "\n",
    "# LightGBM\n",
    "lgb_preds = lgb_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# ✅ Weighted Voting（等重み、必要に応じて調整可能）\n",
    "weights = [1, 1, 1]\n",
    "ensemble_preds = (weights[0] * cat_preds + weights[1] * xgb_preds + weights[2] * lgb_preds) / sum(weights)\n",
    "\n",
    "# ✅ Stackingも作成可能（必要に応じて切替）\n",
    "# stack_X_test = np.vstack([cat_preds, xgb_preds, lgb_preds]).T\n",
    "# ensemble_preds = meta_model.predict_proba(stack_X_test)[:, 1]\n",
    "\n",
    "# ✅ 提出用DataFrame\n",
    "submission = pd.DataFrame({\n",
    "    \"Id\": original_test[\"Id\"],\n",
    "    \"Drafted\": ensemble_preds\n",
    "})\n",
    "\n",
    "# ✅ 保存ディレクトリをプロジェクトルートに作成\n",
    "root_dir = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "save_dir = os.path.join(root_dir, \"submissions\")\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# ✅ Notebook名取得 → ファイル名決定\n",
    "try:\n",
    "    import ipynbname\n",
    "    notebook_path = ipynbname.path()\n",
    "    notebook_name = notebook_path.stem\n",
    "except:\n",
    "    notebook_name = \"21_0705_notebook\"\n",
    "\n",
    "match = re.search(r\"\\d{2}_\\d{4}\", notebook_name)\n",
    "tag = match.group() if match else notebook_name\n",
    "\n",
    "filename = f\"submission_{tag}().csv\"\n",
    "save_path = os.path.join(save_dir, filename)\n",
    "\n",
    "# ✅ 書き出し\n",
    "submission.to_csv(save_path, index=False)\n",
    "print(f\"✅ アンサンブル提出ファイルを保存しました: {save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c99397f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 高相関ペアは存在しません (|r| > 0.9)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ✅ 相関係数計算\n",
    "corr_matrix = X.corr().abs()\n",
    "\n",
    "# ✅ 高相関ペア抽出\n",
    "threshold = 0.90\n",
    "high_corr = np.where(corr_matrix > threshold)\n",
    "high_corr_pairs = []\n",
    "\n",
    "for x, y in zip(*high_corr):\n",
    "    if x < y:\n",
    "        high_corr_pairs.append((\n",
    "            X.columns[x],\n",
    "            X.columns[y],\n",
    "            corr_matrix.iloc[x, y]\n",
    "        ))\n",
    "\n",
    "# ✅ 結果表示\n",
    "if high_corr_pairs:\n",
    "    print(f\"✅ 高相関ペア (|r| > {threshold}):\")\n",
    "    for col1, col2, corr in sorted(high_corr_pairs, key=lambda x: -x[2]):\n",
    "        print(f\"{col1} & {col2}: {corr:.4f}\")\n",
    "else:\n",
    "    print(f\"✅ 高相関ペアは存在しません (|r| > {threshold})\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
